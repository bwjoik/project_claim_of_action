{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import jionlp as jio\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM \n",
    "# load the model and tokenizer\n",
    "device = torch.device('cuda')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"trained_model/small_helmet_418M\")\n",
    "device = torch.device('cuda')\n",
    "#change the model here\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('trained_model/small_helmet_418M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 答案生成區塊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(question):\n",
    "    inputs = tokenizer(question, return_tensors='pt', padding=True, truncation=True, max_length=256).to(device)\n",
    "    out = model.generate(**inputs)\n",
    "    return tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#將問題輸入進去\n",
    "question = ''\n",
    "generate_answer(question)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROUGE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_list = ['01','02','03','04','05','06','07','08','09','10','11','12']\n",
    "for month in month_list:\n",
    "    df = pd.read_csv(f'./dataset/dataset_training/2023{month}.csv')\n",
    "    if month == '01':\n",
    "        df_all = df\n",
    "    else:\n",
    "        df_all = pd.concat([df_all, df], axis=0)\n",
    "\n",
    "data = df_all[['p_claim', 'p_fact']]\n",
    "data = data.rename(columns={'p_claim': 'answer', 'p_fact': 'question'})\n",
    "data = data.dropna()\n",
    "data = data.reset_index(drop=True)\n",
    "data['question'] = data['question'].apply(lambda x: jio.clean_text(x))\n",
    "data['answer'] = data['answer'].apply(lambda x: jio.clean_text(x))\n",
    "data['question'] = data['question'].apply(lambda x: re.sub(r'\\s+', ' ', x))\n",
    "data['answer'] = data['answer'].apply(lambda x: re.sub(r'\\s+', ' ', x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take out the first 100 data for testing\n",
    "data = data.iloc[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "rouge= load_metric(\"rouge\")\n",
    "predictions = []\n",
    "references = []\n",
    "for i in range(len(data)):\n",
    "    question = data['question'][i]\n",
    "    answer = data['answer'][i]\n",
    "    inputs = tokenizer(question, return_tensors='pt', padding=True, truncation=True, max_length=256).to(device)\n",
    "    out = model.generate(**inputs)\n",
    "    prediction = tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "    rouge.compute(predictions=[prediction], references=[answer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge.compute(predictions=[prediction], references=[answer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
